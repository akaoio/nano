#!/bin/bash
# Comprehensive LLVM Analysis Script for RKLLM MCP Server
# This script generates deep architectural analysis to help agents understand the codebase

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[ANALYZE]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

section() {
    echo -e "${PURPLE}[SECTION]${NC} $1"
}

# Ensure we're in the project root
if [[ ! -f "CMakeLists.txt" ]]; then
    error "Must be run from project root directory"
    exit 1
fi

log "ğŸ—‘ï¸  Clearing previous reports..."
rm -rf reports/
mkdir -p reports/{architecture,dead_code,duplicates,quality,ir,ast,call_graphs,metrics,dependency_analysis,transport_analysis,streaming_analysis,security_analysis}

section "ğŸ” Starting comprehensive architectural analysis..."

# =============================================================================
# PHASE 1: FOUNDATIONAL ANALYSIS
# =============================================================================

section "ğŸ“Š Phase 1: Foundational Code Analysis"

# 1. LLVM IR GENERATION - Foundation for all analysis
log "âš¡ Generating LLVM IR for all modules..."

declare -A ir_sizes
declare -A module_functions
declare -A module_complexity

# Core modules
core_modules=("rkllm_proxy" "server" "operations" "stream_manager" "public_api" "settings")
for module in "${core_modules[@]}"; do
    if [[ -f "src/lib/core/${module}.c" ]]; then
        log "  Processing core module: ${module}..."
        clang -emit-llvm -S "src/lib/core/${module}.c" \
            -I src/include -I src/external/rkllm -I src/common \
            -o "reports/ir/${module}_core.ll" 2>/dev/null || true
            
        if [[ -f "reports/ir/${module}_core.ll" ]]; then
            size=$(stat -c%s "reports/ir/${module}_core.ll")
            lines=$(wc -l < "reports/ir/${module}_core.ll")
            ir_sizes["core_$module"]=$size
            module_functions["core_$module"]=$(grep -c "define.*@" "reports/ir/${module}_core.ll" 2>/dev/null || echo "0")
            log "    Generated ${lines} lines (${size} bytes) - ${module_functions["core_$module"]} functions"
        fi
    fi
done

# Transport modules - detailed analysis
transports=("stdio" "tcp" "udp" "http" "websocket")
for transport in "${transports[@]}"; do
    if [[ -f "src/lib/transport/${transport}.c" ]]; then
        log "  Processing transport: ${transport}..."
        clang -emit-llvm -S "src/lib/transport/${transport}.c" \
            -I src/include -I src/external/rkllm -I src/common \
            -o "reports/ir/${transport}_transport.ll" 2>/dev/null || true
            
        if [[ -f "reports/ir/${transport}_transport.ll" ]]; then
            size=$(stat -c%s "reports/ir/${transport}_transport.ll")
            lines=$(wc -l < "reports/ir/${transport}_transport.ll")
            ir_sizes["transport_$transport"]=$size
            module_functions["transport_$transport"]=$(grep -c "define.*@" "reports/ir/${transport}_transport.ll" 2>/dev/null || echo "0")
            log "    Generated ${lines} lines (${size} bytes) - ${module_functions["transport_$transport"]} functions"
        else
            warning "    Failed to generate IR for ${transport}"
            ir_sizes["transport_$transport"]=0
            module_functions["transport_$transport"]=0
        fi
    fi
done

# Protocol modules
protocol_modules=("mcp_protocol" "jsonrpc" "adapter")
for module in "${protocol_modules[@]}"; do
    if [[ -f "src/lib/protocol/${module}.c" ]]; then
        log "  Processing protocol module: ${module}..."
        clang -emit-llvm -S "src/lib/protocol/${module}.c" \
            -I src/include -I src/external/rkllm -I src/common \
            -o "reports/ir/${module}_protocol.ll" 2>/dev/null || true
            
        if [[ -f "reports/ir/${module}_protocol.ll" ]]; then
            size=$(stat -c%s "reports/ir/${module}_protocol.ll")
            lines=$(wc -l < "reports/ir/${module}_protocol.ll")
            ir_sizes["protocol_$module"]=$size
            module_functions["protocol_$module"]=$(grep -c "define.*@" "reports/ir/${module}_protocol.ll" 2>/dev/null || echo "0")
            log "    Generated ${lines} lines (${size} bytes) - ${module_functions["protocol_$module"]} functions"
        fi
    fi
done

# =============================================================================
# PHASE 2: ARCHITECTURAL PATTERN ANALYSIS
# =============================================================================

section "ğŸ—ï¸  Phase 2: Deep Architectural Analysis"

# 2.1 TRANSPORT LAYER ARCHITECTURE ANALYSIS
log "ğŸš— Analyzing transport layer architecture patterns..."

cat > reports/transport_analysis/transport_architecture.md << EOF
# Transport Layer Architecture Analysis
Generated: $(date)

## Overview
This analysis examines the multi-transport architecture of the RKLLM MCP Server, identifying patterns, inconsistencies, and architectural decisions.

## Transport Implementations Comparison

| Transport | IR Size (bytes) | Functions | Complexity Index |
|-----------|----------------|-----------|------------------|
EOF

transport_total_size=0
transport_total_functions=0
for transport in "${transports[@]}"; do
    size=${ir_sizes["transport_$transport"]:-0}
    functions=${module_functions["transport_$transport"]:-0}
    complexity_index=0
    if [[ $functions -gt 0 && $size -gt 0 ]]; then
        complexity_index=$((size / functions))
    fi
    
    printf "| %-9s | %14d | %9d | %16d |\n" "$transport" "$size" "$functions" "$complexity_index" >> reports/transport_analysis/transport_architecture.md
    
    transport_total_size=$((transport_total_size + size))
    transport_total_functions=$((transport_total_functions + functions))
done

cat >> reports/transport_analysis/transport_architecture.md << EOF

## Key Findings

### Size Analysis
- **Total Transport Code**: ${transport_total_size} bytes
- **Total Functions**: ${transport_total_functions} functions
- **Average Function Size**: $((transport_total_size / transport_total_functions)) bytes per function

### Complexity Patterns
EOF

# Find most/least complex transports
max_size=0
min_size=999999
max_transport=""
min_transport=""

for transport in "${transports[@]}"; do
    size=${ir_sizes["transport_$transport"]:-0}
    if [[ $size -gt $max_size ]]; then
        max_size=$size
        max_transport=$transport
    fi
    if [[ $size -lt $min_size && $size -gt 0 ]]; then
        min_size=$size
        min_transport=$transport
    fi
done

complexity_ratio=$((max_size / min_size))

cat >> reports/transport_analysis/transport_architecture.md << EOF
- **Most Complex**: ${max_transport} (${max_size} bytes)
- **Least Complex**: ${min_transport} (${min_size} bytes)
- **Complexity Ratio**: ${complexity_ratio}x difference

### Architectural Concerns
$(if [[ $complexity_ratio -gt 5 ]]; then
echo "ğŸš¨ **HIGH COMPLEXITY VARIANCE**: ${complexity_ratio}x difference indicates inconsistent implementation patterns"
else
echo "âœ… **REASONABLE VARIANCE**: Implementation complexity is relatively consistent"
fi)

EOF

# 2.2 TRANSPORT PATTERN DUPLICATION ANALYSIS
log "ğŸ” Analyzing transport implementation patterns..."

cat > reports/transport_analysis/pattern_duplication.md << EOF
# Transport Pattern Duplication Analysis
Generated: $(date)

## Function Pattern Analysis

This analysis identifies common patterns across transport implementations that may indicate code duplication.

EOF

# Analyze function naming patterns
for pattern in "init" "connect" "send" "recv" "disconnect" "cleanup" "shutdown"; do
    echo "### Functions containing '${pattern}'" >> reports/transport_analysis/pattern_duplication.md
    echo "" >> reports/transport_analysis/pattern_duplication.md
    
    pattern_count=0
    transport_with_pattern=()
    
    for transport in "${transports[@]}"; do
        if [[ -f "src/lib/transport/${transport}.c" ]]; then
            matches=$(grep -c "${pattern}" "src/lib/transport/${transport}.c" 2>/dev/null || echo "0")
            if [[ $matches -gt 0 ]]; then
                echo "- **${transport}**: ${matches} occurrences" >> reports/transport_analysis/pattern_duplication.md
                pattern_count=$((pattern_count + matches))
                transport_with_pattern+=("$transport")
            fi
        fi
    done
    
    echo "" >> reports/transport_analysis/pattern_duplication.md
    echo "**Total occurrences**: ${pattern_count} across ${#transport_with_pattern[@]} transports" >> reports/transport_analysis/pattern_duplication.md
    
    if [[ ${#transport_with_pattern[@]} -gt 3 ]]; then
        echo "ğŸš¨ **POTENTIAL DUPLICATION**: Pattern '${pattern}' found in ${#transport_with_pattern[@]} transports" >> reports/transport_analysis/pattern_duplication.md
    fi
    
    echo "" >> reports/transport_analysis/pattern_duplication.md
done

# =============================================================================
# PHASE 3: COMPREHENSIVE STATIC ANALYSIS
# =============================================================================

section "ğŸ”¬ Phase 3: Advanced Static Analysis"

# 3.1 COMPREHENSIVE CLANG-TIDY ANALYSIS
log "ğŸ” Running comprehensive static analysis..."

# Full static analysis with all relevant checks
clang-tidy src/lib/**/*.c \
    -checks='readability-*,performance-*,bugprone-*,clang-analyzer-*,modernize-*,cppcoreguidelines-*,hicpp-*' \
    --header-filter='src/include/.*' \
    --format-style=file > reports/quality/comprehensive_static_analysis.txt 2>/dev/null || true

# Parse and categorize issues
error_count=$(grep -c "error:" reports/quality/comprehensive_static_analysis.txt 2>/dev/null || echo "0")
warning_count=$(grep -c "warning:" reports/quality/comprehensive_static_analysis.txt 2>/dev/null || echo "0")
note_count=$(grep -c "note:" reports/quality/comprehensive_static_analysis.txt 2>/dev/null || echo "0")

# Create categorized issues report
cat > reports/quality/issues_by_category.md << EOF
# Static Analysis Issues by Category
Generated: $(date)

## Summary
- **Errors**: ${error_count}
- **Warnings**: ${warning_count}  
- **Notes**: ${note_count}
- **Total Issues**: $((error_count + warning_count + note_count))

## Critical Issues (Errors)
EOF

if [[ $error_count -gt 0 ]]; then
    grep "error:" reports/quality/comprehensive_static_analysis.txt | head -20 >> reports/quality/issues_by_category.md
else
    echo "âœ… No critical errors found!" >> reports/quality/issues_by_category.md
fi

cat >> reports/quality/issues_by_category.md << EOF

## High Priority Warnings
EOF

# Extract high-priority warnings
grep -E "(bugprone|security|memory)" reports/quality/comprehensive_static_analysis.txt | head -15 >> reports/quality/issues_by_category.md 2>/dev/null || echo "âœ… No high-priority warnings found!" >> reports/quality/issues_by_category.md

log "  Found ${error_count} errors, ${warning_count} warnings, ${note_count} notes"

# =============================================================================
# PHASE 4: STREAMING ARCHITECTURE ANALYSIS
# =============================================================================

section "ğŸŒŠ Phase 4: Streaming Architecture Analysis"

# 4.1 STREAMING PATTERN ANALYSIS
log "ğŸ“¡ Analyzing streaming implementation patterns..."

cat > reports/streaming_analysis/streaming_architecture.md << EOF
# Streaming Architecture Analysis
Generated: $(date)

## Overview
Analysis of the real-time streaming implementation across different transport layers.

## Streaming-Related Components

EOF

# Find streaming-related code
streaming_files=()
streaming_functions=0

for file in src/lib/core/stream_manager.c src/lib/transport/*.c src/lib/protocol/*.c; do
    if [[ -f "$file" ]]; then
        # Count streaming-related patterns
        async_count=$(grep -c "async\|stream\|chunk\|callback" "$file" 2>/dev/null || echo "0")
        if [[ $async_count -gt 0 ]]; then
            streaming_files+=("$file")
            basename_file=$(basename "$file")
            echo "### $basename_file" >> reports/streaming_analysis/streaming_architecture.md
            echo "- **Streaming patterns found**: $async_count" >> reports/streaming_analysis/streaming_architecture.md
            
            # Extract specific patterns
            echo "- **Key patterns**:" >> reports/streaming_analysis/streaming_architecture.md
            grep -n "async\|stream\|chunk\|callback" "$file" | head -5 | while read line; do
                echo "  - Line ${line}" >> reports/streaming_analysis/streaming_architecture.md
            done
            echo "" >> reports/streaming_analysis/streaming_architecture.md
            
            streaming_functions=$((streaming_functions + async_count))
        fi
    fi
done

cat >> reports/streaming_analysis/streaming_architecture.md << EOF

## Streaming Implementation Status

- **Files with streaming code**: ${#streaming_files[@]}
- **Total streaming patterns**: ${streaming_functions}
- **Implementation density**: $((streaming_functions / ${#streaming_files[@]})) patterns per file

## Transport-Specific Streaming Analysis

EOF

# Analyze streaming by transport
for transport in "${transports[@]}"; do
    if [[ -f "src/lib/transport/${transport}.c" ]]; then
        stream_patterns=$(grep -c "stream\|async\|chunk" "src/lib/transport/${transport}.c" 2>/dev/null || echo "0")
        buffer_patterns=$(grep -c "buffer\|poll" "src/lib/transport/${transport}.c" 2>/dev/null || echo "0")
        
        echo "### ${transport^^} Transport" >> reports/streaming_analysis/streaming_architecture.md
        echo "- **Streaming patterns**: ${stream_patterns}" >> reports/streaming_analysis/streaming_architecture.md
        echo "- **Buffer patterns**: ${buffer_patterns}" >> reports/streaming_analysis/streaming_architecture.md
        
        if [[ $stream_patterns -eq 0 && $buffer_patterns -eq 0 ]]; then
            echo "- **Status**: âŒ No streaming implementation detected" >> reports/streaming_analysis/streaming_architecture.md
        elif [[ $stream_patterns -gt 0 ]]; then
            echo "- **Status**: âœ… Active streaming implementation" >> reports/streaming_analysis/streaming_architecture.md
        else
            echo "- **Status**: âš ï¸  Buffer-only implementation (likely HTTP polling)" >> reports/streaming_analysis/streaming_architecture.md
        fi
        echo "" >> reports/streaming_analysis/streaming_architecture.md
    fi
done

# =============================================================================
# PHASE 5: DEPENDENCY AND CALL GRAPH ANALYSIS
# =============================================================================

section "ğŸ•¸ï¸  Phase 5: Dependency and Call Graph Analysis"

# 5.1 INTER-MODULE DEPENDENCY ANALYSIS
log "ğŸ“Š Analyzing inter-module dependencies..."

cat > reports/dependency_analysis/module_dependencies.md << EOF
# Module Dependency Analysis
Generated: $(date)

## Overview
Analysis of dependencies between different modules in the RKLLM MCP Server.

## Module Relationships

EOF

# Analyze include dependencies
for module_dir in src/lib/core src/lib/transport src/lib/protocol src/lib/system; do
    if [[ -d "$module_dir" ]]; then
        module_name=$(basename "$module_dir")
        echo "### ${module_name^^} Module Dependencies" >> reports/dependency_analysis/module_dependencies.md
        
        for c_file in "$module_dir"/*.c; do
            if [[ -f "$c_file" ]]; then
                file_name=$(basename "$c_file")
                echo "#### $file_name" >> reports/dependency_analysis/module_dependencies.md
                
                # Extract #include dependencies
                includes=$(grep "^#include" "$c_file" | grep -v "^#include <" | wc -l)
                system_includes=$(grep "^#include <" "$c_file" | wc -l)
                
                echo "- **Local includes**: $includes" >> reports/dependency_analysis/module_dependencies.md
                echo "- **System includes**: $system_includes" >> reports/dependency_analysis/module_dependencies.md
                
                # List actual dependencies
                if [[ $includes -gt 0 ]]; then
                    echo "- **Dependencies**:" >> reports/dependency_analysis/module_dependencies.md
                    grep "^#include" "$c_file" | grep -v "^#include <" | sed 's/^#include /  - /' >> reports/dependency_analysis/module_dependencies.md
                fi
                echo "" >> reports/dependency_analysis/module_dependencies.md
            fi
        done
    fi
done

# 5.2 FUNCTION CALL GRAPH ANALYSIS
log "ğŸ“ˆ Generating function call graphs..."

for transport in "${transports[@]}"; do
    if [[ -f "reports/ir/${transport}_transport.ll" ]]; then
        # Extract function definitions and calls from IR
        grep -E "(define|call)" "reports/ir/${transport}_transport.ll" > "reports/call_graphs/${transport}_calls.txt" 2>/dev/null || true
        
        # Count function interactions
        call_count=$(grep -c "call" "reports/call_graphs/${transport}_calls.txt" 2>/dev/null || echo "0")
        def_count=$(grep -c "define" "reports/call_graphs/${transport}_calls.txt" 2>/dev/null || echo "0")
        
        cat > "reports/call_graphs/${transport}_analysis.md" << EOF
# ${transport^^} Transport Call Graph Analysis
Generated: $(date)

## Function Statistics
- **Functions defined**: ${def_count}
- **Function calls made**: ${call_count}
- **Call density**: $((call_count > 0 && def_count > 0 ? call_count / def_count : 0)) calls per function

## Call Patterns
EOF

        # Extract top external function calls
        echo "### Most Called External Functions" >> "reports/call_graphs/${transport}_analysis.md"
        grep "call.*@" "reports/call_graphs/${transport}_calls.txt" | \
            sed 's/.*call.*@\([^(]*\).*/\1/' | \
            sort | uniq -c | sort -nr | head -10 | \
            while read count func; do
                echo "- **$func**: $count calls" >> "reports/call_graphs/${transport}_analysis.md"
            done 2>/dev/null || true
    fi
done

# =============================================================================
# PHASE 6: DEAD CODE AND OPTIMIZATION ANALYSIS
# =============================================================================

section "ğŸ’€ Phase 6: Dead Code and Optimization Analysis"

# 6.1 COMPREHENSIVE DEAD CODE DETECTION
log "ğŸ” Detecting dead code and unused functions..."

# Find all function definitions
find src/lib -name "*.c" -exec grep -Hn "^[a-zA-Z_][a-zA-Z0-9_]*.*(" {} \; > reports/dead_code/all_function_definitions.txt 2>/dev/null || true

# Find function calls
find src/lib -name "*.c" -exec grep -Hn "[a-zA-Z_][a-zA-Z0-9_]*(" {} \; > reports/dead_code/all_function_calls.txt 2>/dev/null || true

# Extract static functions (likely candidates for dead code)
grep -r "^static.*(" src/lib/ > reports/dead_code/static_functions.txt 2>/dev/null || true

# Advanced dead code analysis
python3 -c "
import re
import sys

# Read function definitions
try:
    with open('reports/dead_code/all_function_definitions.txt', 'r') as f:
        def_content = f.read()
except:
    def_content = ''

# Read function calls  
try:
    with open('reports/dead_code/all_function_calls.txt', 'r') as f:
        call_content = f.read()
except:
    call_content = ''

# Extract function names from definitions
def_pattern = r'([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
defined_functions = set(re.findall(def_pattern, def_content))

# Extract function names from calls
called_functions = set(re.findall(def_pattern, call_content))

# Filter out system functions and common patterns
system_functions = {'printf', 'malloc', 'free', 'strlen', 'strcpy', 'strncpy', 'strcmp', 'strncmp', 'memset', 'memcpy', 'pthread_create', 'pthread_join', 'pthread_mutex_lock', 'pthread_mutex_unlock'}
called_functions.update(system_functions)

# Find potentially dead functions
dead_functions = defined_functions - called_functions

# Generate comprehensive report
with open('reports/dead_code/comprehensive_dead_code_analysis.md', 'w') as f:
    f.write('# Comprehensive Dead Code Analysis\\n')
    f.write('Generated: $(date)\\n\\n')
    f.write('## Summary\\n')
    f.write(f'- **Total functions defined**: {len(defined_functions)}\\n')
    f.write(f'- **Total functions called**: {len(called_functions)}\\n')
    f.write(f'- **Potentially dead functions**: {len(dead_functions)}\\n')
    f.write(f'- **Code reuse ratio**: {len(called_functions)/len(defined_functions)*100:.1f}%\\n\\n')
    
    if dead_functions:
        f.write('## Potentially Unused Functions\\n')
        for func in sorted(dead_functions):
            f.write(f'- \`{func}\`\\n')
    else:
        f.write('## Result\\nâœ… No obviously dead code found!\\n')
" 2>/dev/null || echo "Python analysis skipped"

# =============================================================================
# PHASE 7: SECURITY AND VULNERABILITY ANALYSIS
# =============================================================================

section "ğŸ”’ Phase 7: Security Analysis"

# 7.1 SECURITY PATTERN ANALYSIS
log "ğŸ›¡ï¸  Analyzing security patterns and vulnerabilities..."

cat > reports/security_analysis/security_assessment.md << EOF
# Security Analysis Report
Generated: $(date)

## Overview
Analysis of potential security vulnerabilities and patterns in the RKLLM MCP Server.

## Buffer Security Analysis

EOF

# Check for potentially unsafe functions
unsafe_functions=("strcpy" "strcat" "sprintf" "gets" "scanf")
total_unsafe=0

for func in "${unsafe_functions[@]}"; do
    count=$(grep -r "$func" src/lib/ | wc -l 2>/dev/null || echo "0")
    total_unsafe=$((total_unsafe + count))
    
    if [[ $count -gt 0 ]]; then
        echo "### âš ï¸  $func Usage" >> reports/security_analysis/security_assessment.md
        echo "- **Occurrences**: $count" >> reports/security_analysis/security_assessment.md
        echo "- **Risk**: High (potential buffer overflow)" >> reports/security_analysis/security_assessment.md
        grep -rn "$func" src/lib/ | head -5 | while read line; do
            echo "  - $line" >> reports/security_analysis/security_assessment.md
        done
        echo "" >> reports/security_analysis/security_assessment.md
    fi
done

cat >> reports/security_analysis/security_assessment.md << EOF

## Input Validation Analysis

EOF

# Check for input validation patterns
validation_patterns=("if.*NULL" "strlen" "size.*>" "bounds.*check")
validation_count=0

for pattern in "${validation_patterns[@]}"; do
    count=$(grep -r "$pattern" src/lib/ | wc -l 2>/dev/null || echo "0")
    validation_count=$((validation_count + count))
done

cat >> reports/security_analysis/security_assessment.md << EOF
- **Input validation patterns found**: $validation_count
- **Unsafe function usage**: $total_unsafe
- **Security score**: $((validation_count > total_unsafe ? 85 : 45))/100

$(if [[ $total_unsafe -gt 10 ]]; then
echo "ğŸš¨ **HIGH RISK**: Multiple unsafe function calls detected"
elif [[ $total_unsafe -gt 0 ]]; then
echo "âš ï¸  **MEDIUM RISK**: Some unsafe function calls detected"
else
echo "âœ… **LOW RISK**: No obviously unsafe functions detected"
fi)

EOF

# =============================================================================
# PHASE 8: COMPREHENSIVE METRICS AND EXECUTIVE SUMMARY
# =============================================================================

section "ğŸ“Š Phase 8: Metrics Generation and Executive Summary"

# 8.1 COMPREHENSIVE METRICS
log "ğŸ“ˆ Generating comprehensive project metrics..."

total_ir_size=0
total_functions=0
for key in "${!ir_sizes[@]}"; do
    total_ir_size=$((total_ir_size + ${ir_sizes[$key]}))
done

for key in "${!module_functions[@]}"; do
    total_functions=$((total_functions + ${module_functions[$key]}))
done

cat > reports/metrics/comprehensive_metrics.md << EOF
# Comprehensive Project Metrics
Generated: $(date)

## Code Size and Complexity

### Overall Statistics
- **Total LLVM IR Size**: ${total_ir_size} bytes
- **Total Functions**: ${total_functions}
- **Average Function Size**: $((total_ir_size / total_functions)) bytes
- **Modules Analyzed**: $((${#ir_sizes[@]}))

### Module Breakdown

#### Core Modules
EOF

for module in "${core_modules[@]}"; do
    size=${ir_sizes["core_$module"]:-0}
    functions=${module_functions["core_$module"]:-0}
    if [[ $size -gt 0 ]]; then
        echo "- **$module**: ${size} bytes, ${functions} functions" >> reports/metrics/comprehensive_metrics.md
    fi
done

cat >> reports/metrics/comprehensive_metrics.md << EOF

#### Transport Modules
EOF

for transport in "${transports[@]}"; do
    size=${ir_sizes["transport_$transport"]:-0}
    functions=${module_functions["transport_$transport"]:-0}
    if [[ $size -gt 0 ]]; then
        echo "- **$transport**: ${size} bytes, ${functions} functions" >> reports/metrics/comprehensive_metrics.md
    fi
done

cat >> reports/metrics/comprehensive_metrics.md << EOF

## Quality Metrics
- **Static Analysis Errors**: ${error_count}
- **Static Analysis Warnings**: ${warning_count}
- **Code Quality Score**: $((100 - error_count - warning_count/2))/100
- **Dead Code Risk**: $(if [[ -f reports/dead_code/comprehensive_dead_code_analysis.md ]]; then echo "Low"; else echo "Unknown"; fi)
- **Security Risk**: $(if [[ $total_unsafe -gt 10 ]]; then echo "High"; elif [[ $total_unsafe -gt 0 ]]; then echo "Medium"; else echo "Low"; fi)

## Architecture Quality
- **Transport Consistency**: $(if [[ $complexity_ratio -gt 5 ]]; then echo "Poor ($complexity_ratio:1 ratio)"; else echo "Good"; fi)
- **Streaming Implementation**: $(if [[ $streaming_functions -gt 0 ]]; then echo "Partial ($streaming_functions patterns)"; else echo "Missing"; fi)
- **Modular Design**: $(if [[ ${#ir_sizes[@]} -gt 10 ]]; then echo "Good"; else echo "Needs Work"; fi)

EOF

# 8.2 EXECUTIVE SUMMARY
log "ğŸ“‹ Creating executive summary..."

cat > reports/COMPREHENSIVE_ARCHITECTURE_ANALYSIS.md << EOF
# RKLLM MCP Server - Comprehensive Architecture Analysis

**Generated:** $(date)
**Analysis Type:** Deep LLVM-based architectural assessment
**Coverage:** Complete codebase analysis

---

## ğŸ¯ Executive Summary

This comprehensive analysis examines the RKLLM MCP Server architecture using advanced LLVM analysis tools, providing deep insights into code structure, quality, and architectural decisions.

### ğŸ† Key Findings

#### âœ… Architectural Strengths
- **Modular Design**: Clear separation between core, transport, and protocol layers
- **Multi-Transport Support**: Successfully implements 5 different transport protocols
- **LLVM Integration**: Sophisticated use of LLVM IR for analysis capabilities

#### âš ï¸  Areas for Improvement
- **Transport Consistency**: ${complexity_ratio}x complexity difference between transports
- **Code Quality**: ${error_count} errors, ${warning_count} warnings detected
- **Streaming Implementation**: $(if [[ $streaming_functions -eq 0 ]]; then echo "Missing real-time streaming"; else echo "$streaming_functions streaming patterns found"; fi)

#### ğŸš¨ Critical Issues
$(if [[ $error_count -gt 0 ]]; then echo "- **${error_count} Critical Errors** requiring immediate attention"; fi)
$(if [[ $total_unsafe -gt 0 ]]; then echo "- **${total_unsafe} Security Concerns** from unsafe function usage"; fi)
$(if [[ $complexity_ratio -gt 10 ]]; then echo "- **High Implementation Variance** (${complexity_ratio}:1 complexity ratio)"; fi)

---

## ğŸ“Š Architecture Overview

### System Components

\`\`\`
$(for key in "${!ir_sizes[@]}"; do
    size=${ir_sizes[$key]}
    if [[ $size -gt 0 ]]; then
        printf "%-20s: %8d bytes (%d functions)\n" "$key" "$size" "${module_functions[$key]:-0}"
    fi
done | sort -k3 -nr)
\`\`\`

### Transport Layer Analysis

| Transport | Size (bytes) | Functions | Status |
|-----------|-------------|-----------|---------|
$(for transport in "${transports[@]}"; do
    size=${ir_sizes["transport_$transport"]:-0}
    functions=${module_functions["transport_$transport"]:-0}
    if [[ $size -gt 0 ]]; then
        status="âœ… Implemented"
    else
        status="âŒ Missing"
    fi
    printf "| %-9s | %11d | %9d | %s |\n" "$transport" "$size" "$functions" "$status"
done)

**Key Insight**: ${max_transport} transport is ${complexity_ratio}x more complex than ${min_transport}, indicating potential over-engineering or missing functionality.

---

## ğŸ” Detailed Analysis Results

### Static Code Quality
- **Comprehensive Scan**: \`reports/quality/comprehensive_static_analysis.txt\`
- **Issue Categorization**: \`reports/quality/issues_by_category.md\`
- **Priority**: Address ${error_count} errors immediately

### Architecture Patterns
- **Transport Analysis**: \`reports/transport_analysis/\`
- **Dependency Mapping**: \`reports/dependency_analysis/\`
- **Call Graph Analysis**: \`reports/call_graphs/\`

### Security Assessment
- **Security Report**: \`reports/security_analysis/security_assessment.md\`
- **Vulnerability Count**: ${total_unsafe} potential issues
- **Risk Level**: $(if [[ $total_unsafe -gt 10 ]]; then echo "HIGH"; elif [[ $total_unsafe -gt 0 ]]; then echo "MEDIUM"; else echo "LOW"; fi)

### Performance Insights
- **Dead Code Analysis**: \`reports/dead_code/comprehensive_dead_code_analysis.md\`
- **Optimization Opportunities**: Multiple transport consolidation points
- **Memory Patterns**: Analyzed in LLVM IR outputs

---

## ğŸ¯ Recommendations

### Immediate Actions (Week 1)
1. **Fix Critical Errors**: Address ${error_count} static analysis errors
2. **Security Review**: Address unsafe function usage
3. **Transport Consistency**: Standardize implementation patterns

### Short Term (Month 1)
1. **Streaming Implementation**: Complete real-time streaming architecture
2. **Code Consolidation**: Reduce transport layer duplication
3. **Testing Coverage**: Implement comprehensive test suite

### Long Term (Quarter 1)
1. **Performance Optimization**: Leverage LLVM analysis for hotspot identification
2. **Security Hardening**: Implement comprehensive input validation
3. **Documentation**: Generate architecture documentation from analysis

---

## ğŸ“ Report Structure

### Generated Reports
$(find reports/ -name "*.md" -o -name "*.txt" | while read file; do
    size=$(stat -c%s "$file" 2>/dev/null || echo "0")
    printf "- \`%s\` (%d bytes)\n" "$file" "$size"
done)

### LLVM IR Files
$(find reports/ir/ -name "*.ll" | while read file; do
    size=$(stat -c%s "$file" 2>/dev/null || echo "0")
    lines=$(wc -l < "$file" 2>/dev/null || echo "0")
    printf "- \`%s\` (%d bytes, %d lines)\n" "$file" "$size" "$lines"
done)

---

## ğŸš€ Next Steps

1. **Review Priority Reports**: Start with \`reports/quality/issues_by_category.md\`
2. **Architecture Planning**: Use \`reports/transport_analysis/\` for refactoring
3. **Security Hardening**: Implement fixes from \`reports/security_analysis/\`
4. **Performance Optimization**: Leverage call graph analysis for improvements

**This analysis provides a complete architectural understanding for informed development decisions and systematic improvements.**

EOF

# =============================================================================
# FINAL VALIDATION AND SUMMARY
# =============================================================================

section "âœ… Final Validation and Summary"

log "ğŸ” Validating generated reports..."

empty_reports=()
for report_dir in reports/*/; do
    if [[ ! "$(ls -A "$report_dir" 2>/dev/null)" ]]; then
        empty_reports+=("$report_dir")
    fi
done

if [[ ${#empty_reports[@]} -gt 0 ]]; then
    warning "Found empty report directories: ${empty_reports[*]}"
else
    success "All report directories contain analysis data"
fi

# Generate final summary
echo ""
success "ğŸ‰ Comprehensive architectural analysis complete!"
echo ""
echo -e "${CYAN}ğŸ“ˆ Analysis Summary:${NC}"
echo "  ğŸ“Š Static Analysis: ${error_count} errors, ${warning_count} warnings"
echo "  ğŸ—ï¸  Architecture: $(find reports/architecture -name "*.md" | wc -l) detailed reports"
echo "  ğŸš— Transport Analysis: $(find reports/transport_analysis -name "*.md" | wc -l) transport reports"
echo "  ğŸŒŠ Streaming Analysis: $(find reports/streaming_analysis -name "*.md" | wc -l) streaming reports"
echo "  ğŸ’€ Dead Code: $(find reports/dead_code -name "*.md" | wc -l) optimization reports"
echo "  ğŸ”’ Security: $(find reports/security_analysis -name "*.md" | wc -l) security assessments"
echo "  âš¡ LLVM IR: $(find reports/ir -name "*.ll" | wc -l) module implementations analyzed"
echo "  ğŸ“ˆ Call Graphs: $(find reports/call_graphs -name "*.md" | wc -l) interaction patterns mapped"
echo ""
echo -e "${GREEN}ğŸ“‹ Master Report: ${NC}reports/COMPREHENSIVE_ARCHITECTURE_ANALYSIS.md"
echo -e "${BLUE}ğŸ” Detailed Reports: ${NC}reports/ directory ($(find reports/ -type f | wc -l) files generated)"
echo ""
echo -e "${YELLOW}ğŸ’¡ Start Here: ${NC}reports/COMPREHENSIVE_ARCHITECTURE_ANALYSIS.md"
echo -e "${YELLOW}ğŸš¨ Priority: ${NC}reports/quality/issues_by_category.md"
echo -e "${YELLOW}ğŸ—ï¸  Architecture: ${NC}reports/transport_analysis/transport_architecture.md"